{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive_bayes(Question _5).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kCc3QQb_buG",
        "outputId": "da32c597-689f-427f-822c-c1a5f9d9600b"
      },
      "source": [
        "# Importing the important libraries\n",
        "import nltk\n",
        "\n",
        "# Elemenating the stop word\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M3NXccixA57U",
        "outputId": "d21cb0b4-8881-4560-c606-bea11f04a8fa"
      },
      "source": [
        "# Importing tokenizer\n",
        "from string import punctuation\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import os\n",
        "%pylab inline"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWUizglbBO8M"
      },
      "source": [
        "# making stopword stronger by adding punctutaion and more self defined Stopwords\n",
        "punctuation = list(punctuation)\n",
        "Stopwords = stopwords.words('english')\n",
        "Stopwords += punctuation\n",
        "\n",
        "# Using some own defined stopwords to make data more clean\n",
        "Stopwords += ['subject:','from:', 'date:', 'newsgroups:', 'message-id:', 'lines:', 'path:', 'organization:', \n",
        "            'would', 'writes:', 'references:', 'article', 'sender:', 'nntp-posting-host:', 'people', \n",
        "            'university', 'think', 'xref:'] "
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1MPoEY7BDuk"
      },
      "source": [
        "# Defining the train files paths from the dataset 2\n",
        "HARDWARE_TRAIN_DATA_DIR = '/content/drive/MyDrive/Pattern Rec/dataset2/dataset2/train/comp.sys.ibm.pc.hardware' # give your path\n",
        "ELECTRONICS_TRAIN_DATA_DIR = '/content/drive/MyDrive/Pattern Rec/dataset2/dataset2/train/sci.electronics' # give your path"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDtwnuFLjLRg"
      },
      "source": [
        "# Defining the test files paths from the dataset 2\n",
        "HARDWARE_TEST_DATA_DIR = '/content/drive/MyDrive/Pattern Rec/dataset2/dataset2/test/comp.sys.ibm.pc.hardware' # give your path\n",
        "ELECTRONICS_TEST_DATA_DIR = '/content/drive/MyDrive/Pattern Rec/dataset2/dataset2/test/sci.electronics' # give your path "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuQ9D-f4F6XI"
      },
      "source": [
        "# defining a function which loads the train data\n",
        "def load_data(dir):\n",
        "  #loading data\n",
        "  train_data = {}\n",
        "  exce_count =  0\n",
        "  for file in os.listdir(dir):\n",
        "    try:\n",
        "      train_data[file] = filter_data(os.path.join(dir, file))\n",
        "    except Exception as e:\n",
        "        exce_count += 1 \n",
        "  print(\"Data loading successfull\")\n",
        "  print(f\"No of exception occured: {exce_count}\")\n",
        "  return train_data"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "um7aREICKjiK"
      },
      "source": [
        "# This section focus on data preprocessing\n",
        "def filter_data(file):\n",
        "  with open(file) as fd:\n",
        "    try:\n",
        "      data = fd.readlines()\n",
        "      return eliminate_signature(eliminate_header(data))\n",
        "    except Exception as e:\n",
        "      raise encodingexp('Invalid encoding')\n",
        "\n",
        "# Preprocessing step removing signature\n",
        "def eliminate_signature(data):\n",
        "  return re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b', '', eliminate_header(data))\n",
        "\n",
        "# Preprocessing step removing header\n",
        "def eliminate_header(data):\n",
        "  s_idx = 0\n",
        "  for index, value in enumerate(data):\n",
        "    if value == '\\n':\n",
        "      s_idx = index + 1\n",
        "      break\n",
        "  return ''.join(data[s_idx:])  "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V030DsDaMpO6",
        "outputId": "44ce46aa-9ca2-4593-8c67-914a0fed8b84"
      },
      "source": [
        "# Loading training data\n",
        "HARDWARE_TRAIN_DATA = load_data(HARDWARE_TRAIN_DATA_DIR)\n",
        "ELECTRONICS_TRAIN_DATA = load_data(ELECTRONICS_TRAIN_DATA_DIR)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading successfull\n",
            "No of exception occured: 2\n",
            "Data loading successfull\n",
            "No of exception occured: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv56S5ykjdqb",
        "outputId": "46b09bb6-5736-4381-dc8d-81ba52bb4a65"
      },
      "source": [
        "# Loading testing data\n",
        "HARDWARE_TEST_DATA = load_data(HARDWARE_TEST_DATA_DIR)\n",
        "ELECTRONICS_TEST_DATA = load_data(ELECTRONICS_TEST_DATA_DIR)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loading successfull\n",
            "No of exception occured: 3\n",
            "Data loading successfull\n",
            "No of exception occured: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p7A5QScNFEC"
      },
      "source": [
        "# Handling encoding Exception\n",
        "class encodingexp(Exception):\n",
        "  pass"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYU4lt-uWmU1"
      },
      "source": [
        "# Tokenizer class\n",
        "class tokenizer():\n",
        "  @staticmethod\n",
        "  def get_data(data):\n",
        "    _word = []\n",
        "    for word in word_tokenize(data):\n",
        "      if word.lower() not in Stopwords:\n",
        "        _word.append(word)\n",
        "\n",
        "    return _word      \n"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zx05hvpLmykb"
      },
      "source": [
        "# Defining model accuracy method\n",
        "def accuracy(E, H, model):\n",
        "  _acc_score = 0\n",
        "  for message in E.values():\n",
        "     pred = model.predict(message)\n",
        "     if pred == \"Class: Electronics\":\n",
        "       _acc_score += 1\n",
        "\n",
        "  for message in H.values():\n",
        "     pred = model.predict(message)\n",
        "     if pred == \"Class: Hardware\":\n",
        "       _acc_score += 1\n",
        "  accuracy = (_acc_score / (len(E) + len(H))) \n",
        "  return accuracy * 100                "
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_jAJa1GXwky"
      },
      "source": [
        "# designing own Naive bayes classifier\n",
        "class NB_classifier():\n",
        "\n",
        "  def __init__(self):\n",
        "    self._eletronics = 0\n",
        "    self._hardware = 0\n",
        "    self._prob_e = None\n",
        "    self._prob_h = None\n",
        "    # vocabulary and word frequency \n",
        "    self._vocab = {}\n",
        "    self._word_freq = {}\n",
        "    # no of class\n",
        "    self._no_class = 2\n",
        "\n",
        "  def fit(self, ele_data, hard_data):\n",
        "\n",
        "    # Updating vocabulary for both classes\n",
        "    self._add_vocabulary(hard_data)\n",
        "    self._add_vocabulary(ele_data)\n",
        "    \n",
        "    # Updating word frequency\n",
        "    self._add_word_freq(ele_data, hard_data)\n",
        "\n",
        "    self._eletronics = len(ele_data.keys()) \n",
        "    self._hardware = len(hard_data.keys())\n",
        "\n",
        "    # estimating priors\n",
        "    self._prob_e = self._eletronics / (self._eletronics + self._hardware)\n",
        "    self._prob_h = self._hardware / (self._eletronics + self._hardware)\n",
        "\n",
        "  # word frequency updating function\n",
        "  def _add_word_freq(self, ele_data, hard_data):\n",
        "   for word in self._vocab.keys():\n",
        "     doc_freq = [1,1]\n",
        "     for file in ele_data.keys():\n",
        "       if word in ele_data[file]:\n",
        "         doc_freq[0] += 1\n",
        "     for file in hard_data.keys():\n",
        "       if word in hard_data[file]:\n",
        "         doc_freq[1] += 1\n",
        "     self._word_freq[word] = doc_freq\n",
        "  \n",
        "  # to make Prediction\n",
        "  def predict(self, new_data):\n",
        "    _new_prob_e = self._prob_e \n",
        "    _new_prob_h = self._prob_h\n",
        "    _new_token =  tokenizer.get_data(new_data)\n",
        "\n",
        "    for token in _new_token:\n",
        "      if token in self._word_freq:\n",
        "        _new_prob_e *= self._word_freq[token][0] / (self._no_class + self._eletronics + self._hardware )\n",
        "        _new_prob_h *= self._word_freq[token][1] / (self._no_class + self._eletronics + self._hardware )\n",
        "\n",
        "    # Comparing probabilities of two classes and classifying as one class with higher probability \n",
        "    if _new_prob_e > _new_prob_h:\n",
        "      return \"Class: Electronics\"\n",
        "    \n",
        "    elif _new_prob_e < _new_prob_h:\n",
        "      return \"Class: Hardware\"\n",
        "\n",
        "    else:\n",
        "      return \" OOPS! 404 class not found........ \"  \n",
        "  # Updating vocabulary function\n",
        "  def _add_vocabulary(self, collection):\n",
        "    for data in collection.keys():\n",
        "      tokens = tokenizer.get_data(collection[data])\n",
        "      for token in tokens:\n",
        "        if token not in self._vocab:\n",
        "          self._vocab[token] = 1\n",
        "        else:\n",
        "          self._vocab[token] += 1             "
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_C2vSFrqopU"
      },
      "source": [
        "**REFERENCE**:- https://github.com/tanishq9/Text-Classification-20-Newsgroups/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3eIhda9hrMP"
      },
      "source": [
        "# Creating object of our model class\n",
        "clf = NB_classifier()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpqT2cO5hvDi"
      },
      "source": [
        "# Training the model using training data of datset2\n",
        "clf.fit(ELECTRONICS_TRAIN_DATA, HARDWARE_TRAIN_DATA)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOfN_AeroGlb",
        "outputId": "b8ac0279-4b9b-4a01-9ea5-aba09b4944e7"
      },
      "source": [
        "# predicting accuracy on test data of datset2 \n",
        "print(f\"Model accuracy is: {accuracy(ELECTRONICS_TEST_DATA, HARDWARE_TEST_DATA, clf)}\")"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model accuracy is: 80.10269576379974\n"
          ]
        }
      ]
    }
  ]
}